{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6502441",
   "metadata": {},
   "source": [
    "# CodexContinue Data Analysis\n",
    "\n",
    "This notebook demonstrates how to analyze and visualize data from the CodexContinue project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ecd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Set up plotting styles\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a8b9d",
   "metadata": {},
   "source": [
    "## Connect to Project Environment\n",
    "\n",
    "Let's ensure we have access to the CodexContinue project modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fed384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to Python path to access project modules\n",
    "project_root = '/app'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# List available modules in the project\n",
    "print(\"Available directories in the project:\")\n",
    "for item in os.listdir(project_root):\n",
    "    if os.path.isdir(os.path.join(project_root, item)) and not item.startswith('.'):\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e5b37",
   "metadata": {},
   "source": [
    "## Simulated Data Generation\n",
    "\n",
    "For demonstration purposes, we'll generate simulated data that represents user interactions with the CodexContinue system. In a real scenario, you would load this data from a database or API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timestamp range for our simulated data\n",
    "import datetime as dt\n",
    "\n",
    "# Generate dates for the past 30 days\n",
    "end_date = dt.datetime.now()\n",
    "start_date = end_date - dt.timedelta(days=30)\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "# Create simulated user activity data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate random user IDs (100 users)\n",
    "user_ids = [f\"user_{i:03d}\" for i in range(1, 101)]\n",
    "\n",
    "# Create a DataFrame with simulated user activities\n",
    "n_samples = 5000\n",
    "data = {\n",
    "    'timestamp': np.random.choice(dates, n_samples),\n",
    "    'user_id': np.random.choice(user_ids, n_samples),\n",
    "    'action': np.random.choice(['query', 'document_view', 'code_generation', 'code_execution', 'system_config'], n_samples, \n",
    "                             p=[0.4, 0.2, 0.2, 0.15, 0.05]),\n",
    "    'duration_seconds': np.random.exponential(scale=60, size=n_samples),\n",
    "    'success': np.random.choice([True, False], n_samples, p=[0.9, 0.1])\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "activity_df = pd.DataFrame(data)\n",
    "activity_df['date'] = activity_df['timestamp'].dt.date\n",
    "\n",
    "# Display the first few rows\n",
    "activity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98e7d6",
   "metadata": {},
   "source": [
    "## Data Overview and Basic Statistics\n",
    "\n",
    "Let's explore the dataset to understand its structure and basic statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd15599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset shape:\", activity_df.shape)\n",
    "print(\"\\nData types:\")\n",
    "print(activity_df.dtypes)\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "activity_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "activity_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f08548",
   "metadata": {},
   "source": [
    "## User Activity Analysis\n",
    "\n",
    "Let's analyze patterns in user activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee12929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of different actions\n",
    "action_counts = activity_df['action'].value_counts()\n",
    "\n",
    "# Plot the counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=action_counts.index, y=action_counts.values)\n",
    "plt.title('Distribution of User Actions')\n",
    "plt.xlabel('Action Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Success rate by action type\n",
    "success_by_action = activity_df.groupby('action')['success'].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=success_by_action.index, y=success_by_action.values)\n",
    "plt.title('Success Rate by Action Type')\n",
    "plt.xlabel('Action Type')\n",
    "plt.ylabel('Success Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)  # Set y-axis limits for better visualization\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb9c5d",
   "metadata": {},
   "source": [
    "## Temporal Analysis\n",
    "\n",
    "Let's analyze how user activity changes over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33613cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity by date\n",
    "daily_activity = activity_df.groupby('date').size()\n",
    "\n",
    "# Plot daily activity\n",
    "plt.figure(figsize=(12, 6))\n",
    "daily_activity.plot(kind='line', marker='o')\n",
    "plt.title('Daily User Activity')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Actions')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Activity by hour of day\n",
    "activity_df['hour'] = activity_df['timestamp'].dt.hour\n",
    "hourly_activity = activity_df.groupby('hour').size()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "hourly_activity.plot(kind='bar')\n",
    "plt.title('User Activity by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Number of Actions')\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0d90b",
   "metadata": {},
   "source": [
    "## Interactive Visualization with Plotly\n",
    "\n",
    "Let's create an interactive visualization to explore the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive heatmap of user activity by day and hour\n",
    "activity_df['day_of_week'] = activity_df['timestamp'].dt.day_name()\n",
    "day_hour_activity = activity_df.groupby(['day_of_week', 'hour']).size().reset_index(name='count')\n",
    "\n",
    "# Ensure days of week are in correct order\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_hour_activity['day_of_week'] = pd.Categorical(day_hour_activity['day_of_week'], categories=day_order, ordered=True)\n",
    "day_hour_activity = day_hour_activity.sort_values(['day_of_week', 'hour'])\n",
    "\n",
    "# Create the heatmap\n",
    "fig = px.density_heatmap(\n",
    "    day_hour_activity, \n",
    "    x='hour', \n",
    "    y='day_of_week',\n",
    "    z='count',\n",
    "    title='User Activity Heatmap by Day and Hour',\n",
    "    labels={'hour': 'Hour of Day', 'day_of_week': 'Day of Week', 'count': 'Number of Actions'},\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "\n",
    "fig.update_layout(width=900, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e704ce",
   "metadata": {},
   "source": [
    "## User Engagement Metrics\n",
    "\n",
    "Let's calculate some key user engagement metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a602f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily active users (DAU)\n",
    "dau = activity_df.groupby('date')['user_id'].nunique()\n",
    "\n",
    "# Monthly active users (assuming we have 30 days of data)\n",
    "mau = activity_df['user_id'].nunique()\n",
    "\n",
    "# Average actions per user\n",
    "actions_per_user = activity_df.groupby('user_id').size().mean()\n",
    "\n",
    "# Average session duration\n",
    "avg_duration = activity_df['duration_seconds'].mean()\n",
    "\n",
    "# Display metrics\n",
    "metrics = {\n",
    "    'Daily Active Users (Average)': dau.mean(),\n",
    "    'Monthly Active Users': mau,\n",
    "    'Average Actions per User': actions_per_user,\n",
    "    'Average Session Duration (seconds)': avg_duration\n",
    "}\n",
    "\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.2f}\")\n",
    "\n",
    "# Plot DAU trend\n",
    "plt.figure(figsize=(12, 6))\n",
    "dau.plot(kind='line', marker='o')\n",
    "plt.title('Daily Active Users Trend')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Active Users')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebaae0",
   "metadata": {},
   "source": [
    "## User Segmentation\n",
    "\n",
    "Let's segment users based on their activity levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4df69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate activity metrics per user\n",
    "user_activity = activity_df.groupby('user_id').agg({\n",
    "    'timestamp': 'count',              # Total actions\n",
    "    'duration_seconds': 'mean',        # Average session duration\n",
    "    'success': 'mean'                  # Success rate\n",
    "}).rename(columns={'timestamp': 'total_actions'})\n",
    "\n",
    "# Create user segments based on activity\n",
    "def categorize_activity(actions):\n",
    "    if actions < 30:\n",
    "        return 'Low'\n",
    "    elif actions < 70:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "user_activity['activity_level'] = user_activity['total_actions'].apply(categorize_activity)\n",
    "\n",
    "# Display distribution of user segments\n",
    "segment_counts = user_activity['activity_level'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=segment_counts.index, y=segment_counts.values)\n",
    "plt.title('Distribution of User Segments')\n",
    "plt.xlabel('Activity Level')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare metrics across segments\n",
    "segment_metrics = user_activity.groupby('activity_level').agg({\n",
    "    'total_actions': 'mean',\n",
    "    'duration_seconds': 'mean',\n",
    "    'success': 'mean'\n",
    "})\n",
    "\n",
    "segment_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca57427",
   "metadata": {},
   "source": [
    "## Integration with CodexContinue API\n",
    "\n",
    "Let's demonstrate how to connect to the CodexContinue API to fetch real data.\n",
    "\n",
    "> Note: This requires the backend service to be running. If it's not available, this section will fail gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4291790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API interaction example\n",
    "import requests\n",
    "\n",
    "# Backend service URL (using Docker Compose network name)\n",
    "backend_url = 'http://backend:8000'\n",
    "\n",
    "# Function to check if a service is available\n",
    "def check_service(url):\n",
    "    try:\n",
    "        response = requests.get(f\"{url}/health\", timeout=3)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"✅ Service at {url} is available\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Service at {url} returned status code {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Cannot connect to service at {url}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check if backend service is available\n",
    "print(\"Checking backend service availability...\")\n",
    "backend_available = check_service(backend_url)\n",
    "\n",
    "# If backend is available, try to fetch some data\n",
    "if backend_available:\n",
    "    try:\n",
    "        # This is a placeholder - modify based on your actual API endpoints\n",
    "        response = requests.get(f\"{backend_url}/api/stats/summary\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            api_data = response.json()\n",
    "            print(\"\\nData from API:\")\n",
    "            print(api_data)\n",
    "        else:\n",
    "            print(f\"Could not fetch data from API. Status code: {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from API: {e}\")\n",
    "else:\n",
    "    print(\"\\nUsing simulated data as backend service is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf7519",
   "metadata": {},
   "source": [
    "## ML Model Example\n",
    "\n",
    "Let's demonstrate a simple machine learning model using the simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f308876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Use action type to predict success\n",
    "X = activity_df[['duration_seconds']]  # Feature\n",
    "\n",
    "# Add hour of day as a feature\n",
    "X['hour'] = activity_df['hour']\n",
    "\n",
    "# One-hot encode the action type\n",
    "action_dummies = pd.get_dummies(activity_df['action'], prefix='action')\n",
    "X = pd.concat([X, action_dummies], axis=1)\n",
    "\n",
    "y = activity_df['success']  # Target\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Feature Importance for Predicting Success')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0187a1",
   "metadata": {},
   "source": [
    "## Saving Results and Exporting\n",
    "\n",
    "Let's demonstrate how to save our analysis results and export them for use in other parts of the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c36c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for our exports if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"/notebooks/exports\", exist_ok=True)\n",
    "\n",
    "# Export the user activity data to CSV\n",
    "user_activity.to_csv(\"/notebooks/exports/user_activity_summary.csv\")\n",
    "\n",
    "# Export the daily activity data\n",
    "daily_activity_df = daily_activity.reset_index()\n",
    "daily_activity_df.columns = ['date', 'activity_count']\n",
    "daily_activity_df.to_csv(\"/notebooks/exports/daily_activity.csv\", index=False)\n",
    "\n",
    "# Export the model feature importance\n",
    "feature_importance.to_csv(\"/notebooks/exports/feature_importance.csv\", index=False)\n",
    "\n",
    "print(\"Results exported to the '/notebooks/exports' directory.\")\n",
    "print(\"You can access these files from your local machine in the 'notebooks/exports' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc60555",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "We've analyzed simulated user activity data from the CodexContinue project and:\n",
    "\n",
    "1. **Explored user activity patterns** across different dimensions (time, action types)\n",
    "2. **Calculated key engagement metrics** such as DAU, MAU, and average session duration\n",
    "3. **Segmented users** based on their activity levels\n",
    "4. **Built a predictive model** to identify factors that contribute to successful actions\n",
    "5. **Demonstrated API integration** with the backend service\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Connect to real data sources when they become available\n",
    "- Create automated analysis pipelines\n",
    "- Develop more sophisticated ML models for user behavior prediction\n",
    "- Build interactive dashboards for real-time monitoring"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
